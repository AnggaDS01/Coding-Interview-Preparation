{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [E]asy: **Dot Product (Hasil Kali Titik)**\n",
    "1. **Geometrical interpretation of dot product:**\n",
    "   Dot product antara dua vektor itu bisa dilihat sebagai “seberapa besar” dua vektor itu saling mengarah ke arah yang sama. Kalau lo punya dua vektor, misalnya vektor **a** dan **b**, dot product dari mereka adalah:\n",
    "   \n",
    "   $\n",
    "   \\mathbf{a} \\cdot \\mathbf{b} = |\\mathbf{a}| |\\mathbf{b}| \\cos(\\theta)\n",
    "   $\n",
    "   \n",
    "   Di sini, \\(\\theta\\) adalah sudut antara dua vektor. Kalau \\(\\theta = 0^\\circ\\) (artinya dua vektor searah), maka dot product maksimum karena \\(\\cos(0^\\circ) = 1\\). Kalau \\(\\theta = 90^\\circ\\) (artinya dua vektor tegak lurus), dot product-nya nol, karena \\(\\cos(90^\\circ) = 0\\). Jadi, dot product itu kayak \"ukur seberapa selaras\" dua vektor.\n",
    "\n",
    "2. **Maximizing the dot product:**\n",
    "   Buat maksimalkan dot product dari vektor **a** dengan vektor unit **b**, lo perlu buat dua vektor itu searah. Jadi vektor **b** harus sama arah dengan **a** (atau **-a** kalau lo mau negatif maksimum). Contoh rumusnya:\n",
    "   \n",
    "   $\n",
    "   \\mathbf{b} = \\frac{\\mathbf{a}}{|\\mathbf{a}|}\n",
    "   $\n",
    "   Jadi, vektor unit **b** harus sama dengan **a** yang dinormalisasi (dibagi dengan panjangnya).\n",
    "\n",
    "### [M]edium: **Outer Product**\n",
    "1. **Outer Product Calculation:**\n",
    "   Outer product dari dua vektor, **a** dan **b**, berbeda dengan dot product. Outer product menghasilkan matriks (bukan skalar kayak dot product). Kalau **a** adalah vektor berukuran \\(m\\) dan **b** adalah vektor berukuran \\(n\\), outer product-nya:\n",
    "\n",
    "   $\n",
    "   \\mathbf{a} \\otimes \\mathbf{b} = \\mathbf{a} \\mathbf{b}^\\top\n",
    "   $\n",
    "   \n",
    "   Hasilnya adalah matriks berukuran \\(m \\times n\\).\n",
    "\n",
    "2. **Contoh aplikasi outer product di ML:**\n",
    "   Outer product sering dipakai buat modeling interaksi antara fitur-fitur dalam deep learning, terutama di model-model yang kayak **tensor factorization** atau **attention mechanisms** di NLP. Misal, lo punya dua set fitur, dan lo mau modelin interaksi antara dua set itu. Lo bisa bikin outer product mereka, terus pakai hasilnya buat feed ke model.\n",
    "\n",
    "### [E]asy: **Linear Independence**\n",
    "1. **Apa artinya dua vektor linearly independent?**\n",
    "   Dua vektor **a** dan **b** disebut linearly independent kalau gak ada cara lo bisa bikin salah satu dari mereka dengan mengalikan vektor lain dengan skalar. Secara matematis:\n",
    "   \n",
    "   Kalau \\( \\alpha \\mathbf{a} + \\beta \\mathbf{b} = 0 \\), ini cuma mungkin kalau \\( \\alpha = 0 \\) dan \\( \\beta = 0 \\).\n",
    "   \n",
    "   **Aplikasi di ML**: Linear independence penting buat **dimensionality reduction** kayak **Principal Component Analysis (PCA)**, karena lo mau cari set fitur yang gak redundant (gak bisa didapet dari yang lain).\n",
    "\n",
    "### [M]edium: **Basis and Span**\n",
    "1. **Cek kalau dua set vektor punya basis yang sama:**\n",
    "   Set vektor punya basis yang sama kalau span mereka (set semua kombinasi linear) sama. Buat cek ini, lo bisa bikin matriks dari dua set vektor dan cek rank-nya. Kalau rank-nya sama, berarti span mereka sama.\n",
    "\n",
    "2. **Dimensi dari span n vektor di d-dimensi:**\n",
    "   Kalau lo punya \\(n\\) vektor masing-masing di \\(d\\)-dimensi, dimensi span mereka tergantung berapa banyak vektor yang linearly independent. Maksimum dimensi span-nya \\( \\min(n, d) \\).\n",
    "\n",
    "### [E]asy: **Norms**\n",
    "1. **Apa itu norm?**\n",
    "   Norm adalah cara ngukur panjang atau magnitude vektor. Contoh paling umum adalah **Euclidean norm** (atau **L2 norm**):\n",
    "   \n",
    "   $\n",
    "   \\|\\mathbf{a}\\|_2 = \\sqrt{a_1^2 + a_2^2 + \\dots + a_n^2}\n",
    "   $\n",
    "   Ini kayak ngukur panjang garis di ruang Euclidean (ruang yang biasa kita bayangin).\n",
    "\n",
    "### [M]edium: **Norms vs Metrics**\n",
    "1. **Perbedaan norm dan metric:**\n",
    "   Norm ngukur panjang, sedangkan metric ngukur jarak antara dua objek. Setiap norm bisa dipakai buat bikin metric. Contohnya, Euclidean metric:\n",
    "   \n",
    "   $\n",
    "   d(\\mathbf{a}, \\mathbf{b}) = \\|\\mathbf{a} - \\mathbf{b}\\|_2\n",
    "   $\n",
    "   \n",
    "   Tapi gak semua metric berasal dari norm. Contoh metric tanpa norm: **Jaccard similarity** yang sering dipakai buat teks atau gambar.\n",
    "\n",
    "---\n",
    "\n",
    "**Aplikasi di ML:**\n",
    "Norms dan metrics sering dipakai buat optimasi model. Misal, **L2 norm** dipakai di **regularization (Ridge Regression)** buat mencegah model overfitting. Norm juga penting buat ngitung jarak antara titik-titik di ruang fitur, kayak di **K-Nearest Neighbors**.\n",
    "\n",
    "Semoga penjelasannya ngebantu lo lebih siap buat interview nanti, bro! Ada bagian yang pengen lo perdalam lagi?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
